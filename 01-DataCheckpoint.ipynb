{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Saaketh Raghava: Background research, Conceptualization, Writing – original draft, Data Curation\n",
    "- Ethan Lee: Background research, Conceptualization, Writing – original draft\n",
    "- Keyura Valalla: Background research, Conceptualization, Writing – original draft\n",
    "- Daniel Stankoulov: Background research, Conceptualization, Writing – original draft, Data Curation\n",
    "- Sophie Mo: Background research, Conceptualization, Writing – original draft\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which combination of player performance statistics can be optimally integrated into a single aggregate metric that most accurately predicts the winners of the NHL regular-season awards (Hart Memorial Trophy, Vezina Trophy, and Norris Trophy)?\n",
    "\n",
    "Specifically, this research seeks to determine how traditional and advanced statistical measures, such as goals, assists, plus/minus, minutes played, and games played, among others, can be weighted and combined to form a composite indicator of player value that best aligns with historical award outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond the physical grit of the sport, hockey is defined by individual \"changemakers\" who shift a team's dynamic toward a Stanley Cup victory. The NHL recognizes this individual excellence through three primary awards: the Hart Memorial Trophy (Most Valuable Player), the Vezina Trophy (Best Goaltender), and the James Norris Memorial Trophy (Best Defenseman). Together, these honors encompass the core roles of the game: forwards, goalies, and defenders, each contributing uniquely to a team's success through scoring, shot-blocking, and net-minding.\n",
    "\n",
    "Despite their prestige, these awards are often criticized for their subjective nature. The Vezina is voted on by NHL General Managers, while the Hart and Norris are decided by the Professional Hockey Writers' Association. This human element introduces significant bias; for example, analyst JFresh<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)</a> noted a recurring bias against elite players on high-performing teams, where individual value is often overshadowed by the quality of a player’s supporting cast in his blog post 'The Hart Trophy is for the Best Player in the League \"umm actually\" shut up!'. \n",
    "\n",
    "Furthermore, the financial stakes are massive: insider Elliotte Friedman noted on the 32 Thoughts podcast<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)</a> that a franchise star like Connor McDavid (who is a 3 time Hart trophy winner) can generate up to an additional $50 million in team revenue.\n",
    "\n",
    "Our project aims to objectify this evaluation process using data-driven modeling to define what truly constitutes \"the best\" at each position. We are building upon—and refining—methodologies seen in prior sports analytics work. For instance, a project exploring the various relationships between players’ birthdays, their experience vs. goal percentage, and age vs. penalty minutes used a variety of charts to identify and display different categorical and numerical data, such as box and scatter plots <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3)</a>. They clearly organize their data in an easily accessible and understandable way—a method we can adopt to make our report more clear and simple to look at. For one of their hypotheses, the conclusion they drew for the relationship between goal percentage and shooting rates was that there wasn’t a strong linear correlation since the coefficient was 0.2. We can apply these learnings to our own project by accounting for the fact that there may be other factors that influence the value of a player, including being surrounded by a good team, as mentioned before by JFresh. \n",
    " \n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) JFresh. (21 Nov 2025) The Hart Trophy is for the Best Player in the League. *JFresh’s Newsletter*. https://jfresh.substack.com/p/the-hart-trophy-is-for-the-best-player\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Sportsnet. (28 Jan 2026) A Conversation With Josh Doan with Elliotte Friedman & Kyle Bukauskas. *Sportsnet Podcasts*. https://www.sportsnet.ca/podcasts/32-thoughts/\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Sling, S. (n.d.) Final Project Draft: STAT 240. *University of Wisconsin–Madison*. https://pages.cs.wisc.edu/~sling/stat-project/stat240.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Original\n",
    "\n",
    "\n",
    "A player’s plus-minus will have the greatest weight in determining the award outcome. This is because it is the most indicative measure of individual importance for team success in a game. A player can score a lot of goals, but if they are negative, it likely means that they are contributing to losses more than wins because they are contributing to more points lost than gained.\n",
    "\n",
    "\n",
    "#### Updated\n",
    "\n",
    "\n",
    "We hypothesize that a player’s plus-minus will have the most statistically significant weight in determining the Hart and Norris Trophy award winner. This is because it is the most indicative measure of individual importance for team success in a game. A player can score a lot of goals, but if their +- is negative, it likely means that they are contributing to losses more than wins because they are contributing to more points lost than gained. We will use a multivariable regression model to address for team dependency, where we will keep 'teammate_goals' and 'teammate_points' as control variables. This will allow us to determine whether if +- represents individual value or is a simply a product of team success.\n",
    "\n",
    "\n",
    "We believe for the Vezina trophy the most statistically significant weight will be the save percentage. We will create a regression model against 'Shots_Against'.\n",
    "\n",
    "\n",
    "To test which combination of statistics predicts the winner most accurately, we will create a Random Forest model to find feature importance. This will allow us to identify the most optimal combinations of variables that contribute to the players winning the award.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1\n",
    " - Hart Trophy Vote\n",
    " - Taken from Hockey‑Reference award pages for seasons 2008–2025 through beautiful soup\n",
    " - https://www.hockey-reference.com/awards/hart.html\n",
    " - 125 player/season rows after dropping the candidates with <5% of the total vote share.\n",
    " - 7 columns ['Year', 'Place', 'Player', 'Team', 'Position', 'Votes', 'Percent of total votes']\n",
    " - Year: NHL Season associated with the Hart Voting\n",
    " - Player: The Skater or Goalie\n",
    " - Team: What team the player played on for the respective season\n",
    " - position: What role he played for on the team. \n",
    " - Votes: the total Hart points the player got under the leagues 10-7-3-5-1 scoring system. \n",
    " - Percent of Total Votes: player's share of votes over the total votes cast * 100. \n",
    " - The dataset only has players who received signficant Hart votes. Therefore, not every NHLer is in this dataset. \n",
    "### Dataset #2\n",
    "- NHL regular season player and team performance statistics\n",
    "- Taken from MoneyPuck.com for seasons 2008-2025\n",
    "### Dataset #3\n",
    "- Norris Trophy Vote\n",
    " - Taken from Hockey‑Reference award pages for seasons 2008–2025 through beautiful soup\n",
    " - https://www.hockey-reference.com/awards/norris.html\n",
    " - 125 player/season rows after dropping the candidates with <5% of the total vote share.\n",
    " - 7 columns ['Year', 'Place', 'Player', 'Team', 'Position', 'Votes', 'Percent of total votes']\n",
    " - Year: NHL Season associated with the Norris Voting\n",
    " - Player: The Skater \n",
    " - Team: What team the player played on for the respective season\n",
    " - position: What role he played for on the team. \n",
    " - Votes: the total Norris points the player got under the leagues 10-7-3-5-1 scoring system. \n",
    " - Percent of Total Votes: player's share of votes over the total votes cast * 100. \n",
    " - The dataset only has players who received signficant Norris votes. Therefore, not every NHLer is in this dataset. \n",
    "### Dataset #4\n",
    "- Vezina Trophy Vote\n",
    " - Taken from Hockey‑Reference award pages for seasons 2008–2025 through beautiful soup\n",
    " - https://www.hockey-reference.com/awards/vezina.html\n",
    " - 125 player/season rows after dropping the candidates with <5% of the total vote share.\n",
    " - 7 columns ['Year', 'Place', 'Player', 'Team', 'Position', 'Votes', 'Percent of total votes']\n",
    " - Year: NHL Season associated with the Norris Voting\n",
    " - Player: The Skater \n",
    " - Team: What team the player played on for the respective season\n",
    " - position: What role he played for on the team. \n",
    " - Votes: the total Norris points the player got under the leagues 10-7-3-5-1 scoring system. \n",
    " - Percent of Total Votes: player's share of votes over the total votes cast * 100. \n",
    " - The dataset only has players who received signficant Norris votes. Therefore, not every NHLer is in this dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: urllib3, tqdm, idna, charset_normalizer, certifi, requests\n",
      "Successfully installed certifi-2026.1.4 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 tqdm-4.67.3 urllib3-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "%pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 - Hart Trophy Award top Vote Getters  \n",
    "\n",
    "The Professional Hockey Writers’ Association (PHWA) votes on the Hart Trophy. Each voter submits a ranked ballot of five players. The NHL uses a points-based system to convert those rankings into a final score. \n",
    "\n",
    "| Ballot Position | Points |\n",
    "|-----------------|--------|\n",
    "| 1st place       | 10     |\n",
    "| 2nd place       | 7      |\n",
    "| 3rd place       | 5      |\n",
    "| 4th place       | 3      |\n",
    "| 5th place       | 1      |\n",
    "\n",
    "\n",
    "This data set holds the players who received votes for the Hart trophy from 2008-2025. The dataset includes the player's full name, season for which these votes were received, total voting score received using the points system shown above, percent of total vote points (this column seems misleading as the percentages don't add up to 100, but this is due to each voter being able to cast multiple ballots), and a breakdown of number of votes received at each position 1st through 5th. There are additional scoring, goalie stats, and point shares in this dataset, but we collect more complete and advanced metrics for regular season stats in a different dataset, so these will be dropped.\n",
    "\n",
    "Additionally, while some seasons many players received mvp votes, there are always clear frontrunners, so we will be dropping records of players who received less than 5 percent of the percent of total vote points as well, since we only want to predict the winners of awards, and these extra vote getters add too much noise. \n",
    "\n",
    "This dataset has the complete voting data for the Hart Trophy for the seasons we want, so there are no concerns about its validity or introducing any bias from it, as the player who won the most votes wins the trophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction\n",
    "\n",
    "The site we are using for the Hart Trophy voting/winners has the complete data that we need, but it is not easily downloadable. Additionally, the data is split by years, with a different page containing every season's voting result. To get this data and combine it into one usable dataset, we use the \n",
    "script below.\n",
    "\n",
    "The script scrapes the Hockey‑Reference award pages for seasons 2008–2025, forcing UTF‑8 decoding for each page to ensure player names with special characters are handled properly. It locates the Hart Memorial Trophy voting table, and parses its header and body rows into structured records (handling common table quirks like leading index columns and uneven row lengths). For each season it adds a Year field, accumulates all candidate rows, and writes a single UTF‑8 CSV (hart_voting_2008_2025.csv) containing the union of discovered columns. It prints progress and warnings for missing tables and includes a short polite delay between requests to avoid overloading the site.\n",
    "\n",
    "The script was already ran locally, and the csv file was uploaded and is ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/saaketh/anaconda3/envs/atc_data/lib/python3.13/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, lxml, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.14.3 lxml-6.0.2 soupsieve-2.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2008.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2009.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2010.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2011.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2012.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2013.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2014.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2015.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2016.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2017.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2018.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2019.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2020.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2021.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2022.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2023.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2024.html (decoding as UTF-8)\n",
      "Fetching https://www.hockey-reference.com/awards/voting-2025.html (decoding as UTF-8)\n",
      "Saved 405 rows to hart_voting_2008_2025.csv\n",
      "Encoding used for all pages: utf-8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "%pip install beautifulsoup4 lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "\n",
    "BASE_URL = \"https://www.hockey-reference.com/awards/voting-{}.html\"\n",
    "START_YEAR = 2008\n",
    "END_YEAR = 2025\n",
    "OUTPUT_CSV = \"hart_voting_2008_2025.csv\"\n",
    "HEADERS = {\"User-Agent\": \"python-requests/2.x (+https://github.com/)\"}\n",
    "REQUEST_DELAY = 1.0  # seconds between requests to be polite\n",
    "\n",
    "\n",
    "def fetch_page_text_utf8(url):\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    # Force UTF-8 decoding (replace invalid bytes if any)\n",
    "    text = resp.content.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_table_from_soup(soup):\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        cap = table.find(\"caption\")\n",
    "        if cap and \"Hart Memorial Trophy\" in cap.get_text():\n",
    "            return table\n",
    "    header = soup.find(lambda tag: tag.name in (\"h1\", \"h2\", \"h3\", \"h4\") and \"Hart Memorial Trophy\" in tag.get_text())\n",
    "    if header:\n",
    "        t = header.find_next(\"table\")\n",
    "        if t:\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_table_to_dicts(table):\n",
    "    headers = []\n",
    "    thead = table.find(\"thead\")\n",
    "    if thead:\n",
    "        header_rows = thead.find_all(\"tr\")\n",
    "        if header_rows:\n",
    "            last = header_rows[-1]\n",
    "            headers = [th.get_text(strip=True) for th in last.find_all([\"th\", \"td\"])]\n",
    "    if not headers:\n",
    "        first = table.find(\"tr\")\n",
    "        if first:\n",
    "            headers = [cell.get_text(strip=True) for cell in first.find_all([\"th\", \"td\"])]\n",
    "    if headers and headers[0] == \"\":\n",
    "        headers = headers[1:]\n",
    "\n",
    "    tbody = table.find(\"tbody\") or table\n",
    "    rows = []\n",
    "    for tr in tbody.find_all(\"tr\"):\n",
    "        cls = tr.get(\"class\") or []\n",
    "        if \"thead\" in cls or \"divider\" in cls:\n",
    "            continue\n",
    "        cells = [cell.get_text(\" \", strip=True) for cell in tr.find_all([\"th\", \"td\"])]\n",
    "        if not cells:\n",
    "            continue\n",
    "        if len(cells) > len(headers):\n",
    "            if re.match(r\"^\\d+$\", cells[0]):\n",
    "                cells = cells[1:]\n",
    "        if len(cells) < len(headers):\n",
    "            cells += [\"\"] * (len(headers) - len(cells))\n",
    "        elif len(cells) > len(headers):\n",
    "            cells = cells[:len(headers)]\n",
    "        row = OrderedDict((h, v) for h, v in zip(headers, cells))\n",
    "        rows.append(row)\n",
    "    return headers, rows\n",
    "\n",
    "\n",
    "def scrape_year(year):\n",
    "    url = BASE_URL.format(year)\n",
    "    print(f\"Fetching {url} (decoding as UTF-8)\")\n",
    "    html = fetch_page_text_utf8(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    table = extract_table_from_soup(soup)\n",
    "    if table is None:\n",
    "        print(f\"  Warning: Hart table not found for year {year}\")\n",
    "        return [], []\n",
    "    headers, rows = parse_table_to_dicts(table)\n",
    "    return headers, rows\n",
    "\n",
    "\n",
    "def combine_and_write(all_rows, all_headers, filename):\n",
    "    fieldnames = [\"Year\"] + [h for h in all_headers if h != \"Year\"]\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        writer.writeheader()\n",
    "        for r in all_rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "\n",
    "def main():\n",
    "    combined_rows = []\n",
    "    headers_set = []\n",
    "    encodings_used = set()\n",
    "\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        try:\n",
    "            headers, rows = scrape_year(year)\n",
    "            encodings_used.add(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching/parsing year {year}: {e}\")\n",
    "            headers, rows = [], []\n",
    "        for r in rows:\n",
    "            r[\"Year\"] = year\n",
    "            combined_rows.append(r)\n",
    "        for h in headers:\n",
    "            if h not in headers_set and h != \"Year\":\n",
    "                headers_set.append(h)\n",
    "        sleep(REQUEST_DELAY)\n",
    "\n",
    "    if not combined_rows:\n",
    "        print(\"No rows collected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    all_headers = [\"Year\"] + headers_set\n",
    "    for r in combined_rows:\n",
    "        for h in headers_set:\n",
    "            if h not in r:\n",
    "                r[h] = \"\"\n",
    "\n",
    "    combine_and_write(combined_rows, all_headers, OUTPUT_CSV)\n",
    "    print(f\"Saved {len(combined_rows)} rows to {OUTPUT_CSV}\")\n",
    "    print(\"Encoding used for all pages: utf-8\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hart Trophy Data Cleaning/Wrangling\n",
    "\n",
    "Now that we have shown how the dataset was obtained, we will clean and format the data for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw dataframe shape: (405, 26)\n",
      "Columns: ['Year', 'Place', 'Player', 'Age', 'Tm', 'Pos', 'Votes', 'Vote%', '1st', '2nd', '3rd', '4th', '5th', 'G', 'A', 'PTS', '+/-', 'W', 'L', 'T/O', 'GAA', 'SV%', 'OPS', 'DPS', 'GPS', 'PS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Place</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Vote%</th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "      <th>...</th>\n",
       "      <th>+/-</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T/O</th>\n",
       "      <th>GAA</th>\n",
       "      <th>SV%</th>\n",
       "      <th>OPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>GPS</th>\n",
       "      <th>PS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Alex Ovechkin</td>\n",
       "      <td>22</td>\n",
       "      <td>WSH</td>\n",
       "      <td>LW</td>\n",
       "      <td>1313</td>\n",
       "      <td>97.99</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>Evgeni Malkin</td>\n",
       "      <td>21</td>\n",
       "      <td>PIT</td>\n",
       "      <td>C</td>\n",
       "      <td>659</td>\n",
       "      <td>49.18</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>Jarome Iginla</td>\n",
       "      <td>30</td>\n",
       "      <td>CGY</td>\n",
       "      <td>RW</td>\n",
       "      <td>565</td>\n",
       "      <td>42.16</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>Nicklas Lidström</td>\n",
       "      <td>37</td>\n",
       "      <td>DET</td>\n",
       "      <td>D</td>\n",
       "      <td>246</td>\n",
       "      <td>18.36</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>Martin Brodeur</td>\n",
       "      <td>35</td>\n",
       "      <td>NJD</td>\n",
       "      <td>G</td>\n",
       "      <td>239</td>\n",
       "      <td>17.84</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2.17</td>\n",
       "      <td>.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Place            Player Age   Tm Pos Votes  Vote%  1st 2nd  ... +/-  \\\n",
       "0  2008     1     Alex Ovechkin  22  WSH  LW  1313  97.99  128   4  ...  28   \n",
       "1  2008     2     Evgeni Malkin  21  PIT   C   659  49.18    1  66  ...  16   \n",
       "2  2008     3     Jarome Iginla  30  CGY  RW   565  42.16    2  41  ...  27   \n",
       "3  2008     4  Nicklas Lidström  37  DET   D   246  18.36    2   7  ...  40   \n",
       "4  2008     5    Martin Brodeur  35  NJD   G   239  17.84    1   8  ...   0   \n",
       "\n",
       "     W    L  T/O   GAA   SV%   OPS  DPS   GPS    PS  \n",
       "0  NaN  NaN  NaN   NaN   NaN  14.1  3.1   0.0  17.2  \n",
       "1  NaN  NaN  NaN   NaN   NaN  11.5  2.4   0.0  13.9  \n",
       "2  NaN  NaN  NaN   NaN   NaN  11.3  2.9   0.0  14.2  \n",
       "3  NaN  NaN  NaN   NaN   NaN   6.4  8.1   0.0  14.4  \n",
       "4   44   27    6  2.17  .920   0.0  0.0  15.5  15.5  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell contains the initial setup and loading of the data\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Setting up the working directories\n",
    "RAW_PATH = Path('data/00-raw/hart_voting_2008_2025.csv')\n",
    "INTERIM_DIR = Path('data/01-interim')\n",
    "PROCESSED_DIR = Path('data/02-processed')\n",
    "\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Making sure the raw data is present\n",
    "assert RAW_PATH.exists()\n",
    "\n",
    "# Loading the dataset\n",
    "df_raw = pd.read_csv(RAW_PATH, dtype=str, encoding=\"utf-8\")\n",
    "print(\"Loaded raw dataframe shape:\", df_raw.shape)\n",
    "print(\"Columns:\", df_raw.columns.tolist())\n",
    "display(df_raw.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop ['W', 'T/O', 'L', 'OPS', '5th', '4th', 'GPS', 'PS', 'G', '+/-', '3rd', 'DPS', 'SV%', 'GAA', 'A', 'PTS', '1st', '2nd', 'Age']\n",
      "Dropped 280 rows with <5% of season points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Place</th>\n",
       "      <th>Player</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Vote%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Alex Ovechkin</td>\n",
       "      <td>WSH</td>\n",
       "      <td>LW</td>\n",
       "      <td>1313</td>\n",
       "      <td>97.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>Evgeni Malkin</td>\n",
       "      <td>PIT</td>\n",
       "      <td>C</td>\n",
       "      <td>659</td>\n",
       "      <td>49.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>Jarome Iginla</td>\n",
       "      <td>CGY</td>\n",
       "      <td>RW</td>\n",
       "      <td>565</td>\n",
       "      <td>42.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>Nicklas Lidström</td>\n",
       "      <td>DET</td>\n",
       "      <td>D</td>\n",
       "      <td>246</td>\n",
       "      <td>18.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>Martin Brodeur</td>\n",
       "      <td>NJD</td>\n",
       "      <td>G</td>\n",
       "      <td>239</td>\n",
       "      <td>17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Place            Player   Tm Pos Votes  Vote%\n",
       "0  2008     1     Alex Ovechkin  WSH  LW  1313  97.99\n",
       "1  2008     2     Evgeni Malkin  PIT   C   659  49.18\n",
       "2  2008     3     Jarome Iginla  CGY  RW   565  42.16\n",
       "3  2008     4  Nicklas Lidström  DET   D   246  18.36\n",
       "4  2008     5    Martin Brodeur  NJD   G   239  17.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initial cleaning and whitespace normalization\n",
    "df = df_raw.copy()\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == object:\n",
    "        df[c] = df[c].str.strip()\n",
    "\n",
    "\n",
    "# Drop columns we don't care about by keyword matching\n",
    "drop_keywords = ['Age', '1st', '2nd', '3rd', '4th', '5th', 'G', 'A', 'PTS', '+/-', 'W', 'L', 'T/O', 'GAA', 'SV%', 'OPS', 'DPS', 'GPS', 'PS']\n",
    "to_drop = list(set(drop_keywords))\n",
    "print(\"Columns to drop\", to_drop)\n",
    "df = df.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "\n",
    "# Remove rows with <5% of season points\n",
    "before = len(df)\n",
    "df = df[df['Vote%'].astype(float).fillna(0) >= 5.0]\n",
    "after = len(df)\n",
    "print(f\"Dropped {before-after} rows with <5% of season points\")\n",
    "\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = PROCESSED_DIR / \"hart_voting_2008_2025_processed.csv\" \n",
    "df.to_csv(processed_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year      0\n",
       "Place     0\n",
       "Player    0\n",
       "Tm        0\n",
       "Pos       0\n",
       "Votes     0\n",
       "Vote%     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset is tidy, because Each variable is a column, each observation is a row, and each value is atomic \n",
    "df = pd.read_csv(processed_path)\n",
    "\n",
    "# Size of the dataset\n",
    "df.shape\n",
    "\n",
    "# Show missing fields (dataset is complete, nothing is missing)\n",
    "df.isna().sum()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "NHL regular season player and team performance statistics (2008 - 2024)\n",
    "\n",
    "This dataset is a collection of regular-season performance metrics for NHL skaters, goaltenders, and teams, spanning from 2008 to 2024. It combines traditional statistics (like goals and assists) with advanced analytical measures (like Expected Goals and Fenwick percentages) to provide a specific view of player impact. The data is structured to allow for multi-level analysis, ranging from individual player \"situations\" (e.g., 5-on-5, Power Play, Penalty Kill) to team-level aggregate success.\n",
    "\n",
    "1. Important Metrics and Interpretation\n",
    "- Time on Ice (icetime): Recorded in seconds as an integer(often converted to minutes for analysis). In this dataset, the average NHL regular player plays around 793 minutes per season. Elite “changemakers” will most likely have a higher ice time because they make more impact for the team; therefore, the rationale is that the coaches would want to play them longer.\n",
    "- Expected Goals: Recorded in the unit of goals as an integer. A high Expected Goals count relative to actual goals can indicate a player who is generating high-quality chances but experiencing \"bad luck\" or facing elite goaltending.\n",
    "- Games Played: Recorded in the units of games in integers. “Games Played” is an important metric to consider because players with a higher “Games Played” value mean that they get more opportunities to score goals or block shots in the goalie's perspective, therefore reducing and normalizing the weight of their contributions to the team. A player with 10 goals in 100 games would be much less valued than a player with 10 goals in 10 games for example.\n",
    "\n",
    "2. Major Concerns and Biases\n",
    "- Home Team Bias: Many of the metrics in this dataset—specifically hits, takeaways, and giveaways—are recorded by human off-ice officials at the arena. Historical analysis has shown that certain arenas are \"more generous\" in awarding these stats to the home team, which can introduce geographic noise into the data.\n",
    "- Team Strength bias: As mentioned in our hypothesis, raw +/- is heavily influenced by the quality of a player's teammates and goaltender. A player on a rebuilding team might have elite individual defensive metrics (like shot suppression) but a negative +/- because their goalie has a low save percentage. \n",
    "- Survival Bias: This dataset only tracks players who successfully made an NHL roster. It does not include the performance of \"replacement level\" players in the AHL who were never called up. This creates a skewed baseline where \"average\" in this dataset actually represents the top 1% of all professional hockey players.\n",
    "- Rule and Style Evolution: The dataset spans 16 years, a period during which the NHL underwent significant shifts in playstyle (e.g., the move away from the \"clutch and grab\" era to a speed-based game). Scoring rates and the value of +/- may have shifted over time, meaning a +20 in 2010 might not represent the same level of dominance as a +20 in 2024.\n",
    "\n",
    "We downloaded these 4 datasets from MoneyPuck.com\n",
    "https://www.moneypuck.com/data.htm\n",
    "\n",
    "It is important to note that, we focus our cleaning on the skater and goalie tables which can directly be related to the Hart, Norris, and Vezina datasets through Name and season. We leave the line and team-level season tables for potential future feature engineering, if we deem it necessary later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_skaters_raw shape: (8020, 36)\n",
      "df_goalies_raw shape: (8020, 36)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "\n",
    "# Setting up the working directories\n",
    "raw_data_dir = Path('data/00-raw')\n",
    "processed_data_dir = Path('data/01-interim')\n",
    "processed_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert raw_data_dir.exists()\n",
    "\n",
    "skaters_path = raw_data_dir / 'season_lvl_goalies_raw.csv'\n",
    "goalies_path = raw_data_dir / 'season_lvl_goalies_raw.csv'\n",
    "\n",
    "df_skaters_raw = pd.read_csv(skaters_path)\n",
    "df_goalies_raw = pd.read_csv(goalies_path)\n",
    "\n",
    "\n",
    "print('df_skaters_raw shape:', df_skaters_raw.shape)\n",
    "print('df_goalies_raw shape:', df_goalies_raw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>games_played</th>\n",
       "      <th>icetime</th>\n",
       "      <th>xGoals</th>\n",
       "      <th>goals</th>\n",
       "      <th>...</th>\n",
       "      <th>mediumDangerShots</th>\n",
       "      <th>highDangerShots</th>\n",
       "      <th>lowDangerxGoals</th>\n",
       "      <th>mediumDangerxGoals</th>\n",
       "      <th>highDangerxGoals</th>\n",
       "      <th>lowDangerGoals</th>\n",
       "      <th>mediumDangerGoals</th>\n",
       "      <th>highDangerGoals</th>\n",
       "      <th>penalityMinutes</th>\n",
       "      <th>penalties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>other</td>\n",
       "      <td>46</td>\n",
       "      <td>5232.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.89</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>all</td>\n",
       "      <td>46</td>\n",
       "      <td>157455.0</td>\n",
       "      <td>129.82</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.02</td>\n",
       "      <td>43.49</td>\n",
       "      <td>40.30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on5</td>\n",
       "      <td>46</td>\n",
       "      <td>116930.0</td>\n",
       "      <td>80.79</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>35.26</td>\n",
       "      <td>29.92</td>\n",
       "      <td>15.61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>4on5</td>\n",
       "      <td>46</td>\n",
       "      <td>17502.0</td>\n",
       "      <td>31.77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>8.57</td>\n",
       "      <td>16.99</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on4</td>\n",
       "      <td>46</td>\n",
       "      <td>17791.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerId  season           name team position situation  games_played  \\\n",
       "0   8470140    2008  Kari Lehtonen  ATL        G     other            46   \n",
       "1   8470140    2008  Kari Lehtonen  ATL        G       all            46   \n",
       "2   8470140    2008  Kari Lehtonen  ATL        G      5on5            46   \n",
       "3   8470140    2008  Kari Lehtonen  ATL        G      4on5            46   \n",
       "4   8470140    2008  Kari Lehtonen  ATL        G      5on4            46   \n",
       "\n",
       "    icetime  xGoals  goals  ...  mediumDangerShots  highDangerShots  \\\n",
       "0    5232.0   11.45   12.0  ...               23.0             15.0   \n",
       "1  157455.0  129.82  134.0  ...              361.0            110.0   \n",
       "2  116930.0   80.79   80.0  ...              253.0             54.0   \n",
       "3   17502.0   31.77   36.0  ...               69.0             35.0   \n",
       "4   17791.0    4.94    6.0  ...               14.0              6.0   \n",
       "\n",
       "   lowDangerxGoals  mediumDangerxGoals  highDangerxGoals  lowDangerGoals  \\\n",
       "0             2.67                2.89              5.89             7.0   \n",
       "1            46.02               43.49             40.30            42.0   \n",
       "2            35.26               29.92             15.61            26.0   \n",
       "3             6.22                8.57             16.99             7.0   \n",
       "4             1.33                1.78              1.82             2.0   \n",
       "\n",
       "   mediumDangerGoals  highDangerGoals  penalityMinutes  penalties  \n",
       "0                1.0              4.0              0.0        0.0  \n",
       "1               41.0             51.0              6.0        3.0  \n",
       "2               34.0             20.0              6.0        3.0  \n",
       "3                3.0             26.0              0.0        0.0  \n",
       "4                3.0              1.0              0.0        0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skaters_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>games_played</th>\n",
       "      <th>icetime</th>\n",
       "      <th>xGoals</th>\n",
       "      <th>goals</th>\n",
       "      <th>...</th>\n",
       "      <th>mediumDangerShots</th>\n",
       "      <th>highDangerShots</th>\n",
       "      <th>lowDangerxGoals</th>\n",
       "      <th>mediumDangerxGoals</th>\n",
       "      <th>highDangerxGoals</th>\n",
       "      <th>lowDangerGoals</th>\n",
       "      <th>mediumDangerGoals</th>\n",
       "      <th>highDangerGoals</th>\n",
       "      <th>penalityMinutes</th>\n",
       "      <th>penalties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>other</td>\n",
       "      <td>46</td>\n",
       "      <td>5232.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.89</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>all</td>\n",
       "      <td>46</td>\n",
       "      <td>157455.0</td>\n",
       "      <td>129.82</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.02</td>\n",
       "      <td>43.49</td>\n",
       "      <td>40.30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on5</td>\n",
       "      <td>46</td>\n",
       "      <td>116930.0</td>\n",
       "      <td>80.79</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>35.26</td>\n",
       "      <td>29.92</td>\n",
       "      <td>15.61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>4on5</td>\n",
       "      <td>46</td>\n",
       "      <td>17502.0</td>\n",
       "      <td>31.77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>8.57</td>\n",
       "      <td>16.99</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on4</td>\n",
       "      <td>46</td>\n",
       "      <td>17791.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerId  season           name team position situation  games_played  \\\n",
       "0   8470140    2008  Kari Lehtonen  ATL        G     other            46   \n",
       "1   8470140    2008  Kari Lehtonen  ATL        G       all            46   \n",
       "2   8470140    2008  Kari Lehtonen  ATL        G      5on5            46   \n",
       "3   8470140    2008  Kari Lehtonen  ATL        G      4on5            46   \n",
       "4   8470140    2008  Kari Lehtonen  ATL        G      5on4            46   \n",
       "\n",
       "    icetime  xGoals  goals  ...  mediumDangerShots  highDangerShots  \\\n",
       "0    5232.0   11.45   12.0  ...               23.0             15.0   \n",
       "1  157455.0  129.82  134.0  ...              361.0            110.0   \n",
       "2  116930.0   80.79   80.0  ...              253.0             54.0   \n",
       "3   17502.0   31.77   36.0  ...               69.0             35.0   \n",
       "4   17791.0    4.94    6.0  ...               14.0              6.0   \n",
       "\n",
       "   lowDangerxGoals  mediumDangerxGoals  highDangerxGoals  lowDangerGoals  \\\n",
       "0             2.67                2.89              5.89             7.0   \n",
       "1            46.02               43.49             40.30            42.0   \n",
       "2            35.26               29.92             15.61            26.0   \n",
       "3             6.22                8.57             16.99             7.0   \n",
       "4             1.33                1.78              1.82             2.0   \n",
       "\n",
       "   mediumDangerGoals  highDangerGoals  penalityMinutes  penalties  \n",
       "0                1.0              4.0              0.0        0.0  \n",
       "1               41.0             51.0              6.0        3.0  \n",
       "2               34.0             20.0              6.0        3.0  \n",
       "3                3.0             26.0              0.0        0.0  \n",
       "4                3.0              1.0              0.0        0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_skater_col =['playerId', 'season', 'name', 'team', 'position', 'situation',\n",
    "       'games_played', 'icetime', 'xGoals', 'goals', 'unblocked_shot_attempts',\n",
    "       'xPlayStopped', 'playStopped', 'xPlayContinuedInZone',\n",
    "       'flurryAdjustedxGoals', 'lowDangerShots',\n",
    "       'mediumDangerShots', 'highDangerShots', 'lowDangerxGoals',\n",
    "       'mediumDangerxGoals', 'highDangerxGoals', 'lowDangerGoals',\n",
    "       'mediumDangerGoals', 'highDangerGoals', \n",
    "       'penalityMinutes', 'penalties']\n",
    "df_skaters_raw=df_skaters_raw[cleaned_skater_col]\n",
    "df_skaters_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned skaters_df shape: (8020, 26)\n"
     ]
    }
   ],
   "source": [
    "if 'games_played' in df_skaters_raw.columns:\n",
    "    df_skaters_interim = df_skaters_raw[df_skaters_raw['games_played'] > 0]\n",
    "\n",
    "print(\"Cleaned skaters_df shape:\", df_skaters_interim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skaters_interim.isna().sum()\n",
    "df_skaters_interim.to_csv(processed_data_dir / 'season_lvl_skaters_interim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>season</th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>situation</th>\n",
       "      <th>games_played</th>\n",
       "      <th>icetime</th>\n",
       "      <th>xGoals</th>\n",
       "      <th>goals</th>\n",
       "      <th>...</th>\n",
       "      <th>highDangerShots</th>\n",
       "      <th>lowDangerxGoals</th>\n",
       "      <th>mediumDangerxGoals</th>\n",
       "      <th>highDangerxGoals</th>\n",
       "      <th>lowDangerGoals</th>\n",
       "      <th>mediumDangerGoals</th>\n",
       "      <th>highDangerGoals</th>\n",
       "      <th>blocked_shot_attempts</th>\n",
       "      <th>penalityMinutes</th>\n",
       "      <th>penalties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>other</td>\n",
       "      <td>46</td>\n",
       "      <td>5232.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.89</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>all</td>\n",
       "      <td>46</td>\n",
       "      <td>157455.0</td>\n",
       "      <td>129.82</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.02</td>\n",
       "      <td>43.49</td>\n",
       "      <td>40.30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on5</td>\n",
       "      <td>46</td>\n",
       "      <td>116930.0</td>\n",
       "      <td>80.79</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>35.26</td>\n",
       "      <td>29.92</td>\n",
       "      <td>15.61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>4on5</td>\n",
       "      <td>46</td>\n",
       "      <td>17502.0</td>\n",
       "      <td>31.77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>8.57</td>\n",
       "      <td>16.99</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8470140</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kari Lehtonen</td>\n",
       "      <td>ATL</td>\n",
       "      <td>G</td>\n",
       "      <td>5on4</td>\n",
       "      <td>46</td>\n",
       "      <td>17791.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerId  season           name team position situation  games_played  \\\n",
       "0   8470140    2008  Kari Lehtonen  ATL        G     other            46   \n",
       "1   8470140    2008  Kari Lehtonen  ATL        G       all            46   \n",
       "2   8470140    2008  Kari Lehtonen  ATL        G      5on5            46   \n",
       "3   8470140    2008  Kari Lehtonen  ATL        G      4on5            46   \n",
       "4   8470140    2008  Kari Lehtonen  ATL        G      5on4            46   \n",
       "\n",
       "    icetime  xGoals  goals  ...  highDangerShots  lowDangerxGoals  \\\n",
       "0    5232.0   11.45   12.0  ...             15.0             2.67   \n",
       "1  157455.0  129.82  134.0  ...            110.0            46.02   \n",
       "2  116930.0   80.79   80.0  ...             54.0            35.26   \n",
       "3   17502.0   31.77   36.0  ...             35.0             6.22   \n",
       "4   17791.0    4.94    6.0  ...              6.0             1.33   \n",
       "\n",
       "   mediumDangerxGoals  highDangerxGoals  lowDangerGoals  mediumDangerGoals  \\\n",
       "0                2.89              5.89             7.0                1.0   \n",
       "1               43.49             40.30            42.0               41.0   \n",
       "2               29.92             15.61            26.0               34.0   \n",
       "3                8.57             16.99             7.0                3.0   \n",
       "4                1.78              1.82             2.0                3.0   \n",
       "\n",
       "   highDangerGoals  blocked_shot_attempts  penalityMinutes  penalties  \n",
       "0              4.0                   22.0              0.0        0.0  \n",
       "1             51.0                  605.0              6.0        3.0  \n",
       "2             20.0                  434.0              6.0        3.0  \n",
       "3             26.0                  137.0              0.0        0.0  \n",
       "4              1.0                   10.0              0.0        0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goalies_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playerId', 'season', 'name', 'team', 'position', 'situation',\n",
       "       'games_played', 'icetime', 'xGoals', 'goals', 'unblocked_shot_attempts',\n",
       "       'xRebounds', 'rebounds', 'xFreeze', 'freeze', 'xOnGoal', 'ongoal',\n",
       "       'xPlayStopped', 'playStopped', 'xPlayContinuedInZone',\n",
       "       'playContinuedInZone', 'xPlayContinuedOutsideZone',\n",
       "       'playContinuedOutsideZone', 'flurryAdjustedxGoals', 'lowDangerShots',\n",
       "       'mediumDangerShots', 'highDangerShots', 'lowDangerxGoals',\n",
       "       'mediumDangerxGoals', 'highDangerxGoals', 'lowDangerGoals',\n",
       "       'mediumDangerGoals', 'highDangerGoals', 'blocked_shot_attempts',\n",
       "       'penalityMinutes', 'penalties'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goalies_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned goalies_df shape: (8020, 24)\n"
     ]
    }
   ],
   "source": [
    "cleaned_goalies_col = ['playerId', 'season', 'name', 'team', 'position', 'situation',\n",
    "       'games_played', 'icetime', 'xGoals', 'goals', 'unblocked_shot_attempts',\n",
    "       'flurryAdjustedxGoals', 'lowDangerShots',\n",
    "       'mediumDangerShots', 'highDangerShots', 'lowDangerxGoals',\n",
    "       'mediumDangerxGoals', 'highDangerxGoals', 'lowDangerGoals',\n",
    "       'mediumDangerGoals', 'highDangerGoals', 'blocked_shot_attempts',\n",
    "       'penalityMinutes', 'penalties']\n",
    "\n",
    "df_goalies_interim = df_goalies_raw[cleaned_goalies_col]\n",
    "\n",
    "if 'games_played' in df_goalies_interim.columns:\n",
    "    df_goalies_interim = df_goalies_interim[df_goalies_interim['games_played'] > 0]\n",
    "print(\"Cleaned goalies_df shape:\", df_goalies_interim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "playerId                   0\n",
       "season                     0\n",
       "name                       0\n",
       "team                       0\n",
       "position                   0\n",
       "situation                  0\n",
       "games_played               0\n",
       "icetime                    0\n",
       "xGoals                     0\n",
       "goals                      0\n",
       "unblocked_shot_attempts    0\n",
       "flurryAdjustedxGoals       0\n",
       "lowDangerShots             0\n",
       "mediumDangerShots          0\n",
       "highDangerShots            0\n",
       "lowDangerxGoals            0\n",
       "mediumDangerxGoals         0\n",
       "highDangerxGoals           0\n",
       "lowDangerGoals             0\n",
       "mediumDangerGoals          0\n",
       "highDangerGoals            0\n",
       "blocked_shot_attempts      0\n",
       "penalityMinutes            0\n",
       "penalties                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goalies_interim.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goalies_interim.to_csv(processed_data_dir / 'season_lvl_goalies_interim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3 - Norris Trophy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "#### Original\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> NHL Players are professional athletes who are aware their stats and names are being tracked and collected by the league and the teams they play for/against.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> The data consists entirely of public figures such as NHL athletes and public award voting history. Therefore, there is no risk of Personally Identifiable Information (PII).\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    " #### Updated\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> NHL Players are professional athletes who are aware their stats and names are being tracked and collected by the league and the teams they play for/against.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Some sources of bias include the “East Coast Bias” where players in the eastern time zone are favoured due to game visibility. Another source of bias is reputation bias where veterans receive more votes based on past performance rather than their performance in the current season. To mitigate these biases, we acknowledge that our model predicts voter behavior rather than objective “on-ice” value. \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> The data consists entirely of public figures such as NHL athletes and public award voting history. Therefore, there is no risk of Personally Identifiable Information (PII).\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> As of the 2023-24 season, approximately 90% of the league identifies as white. To ensure our model doesn’t favor specific demographics, we will audit the “Feature Importance” in our model to ensure that it remains tied to on-ice production metrics. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The data provided from NHL is publicly available, meaning that we do not need to protect and secure data as it is already released as a public record.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> An individual has already consented to having their records released via NHL data, meaning that we do not need to remove their information.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> Since the data is derived from public NHL records and used for an academic/research project, we will retain the cleaned dataset for the duration of the analysis and peer review. Once the project is finalized and the report is submitted, the specific processed CSVs/DataFrames will be archived or deleted, as the raw data remains perpetually accessible via the NHL API.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We address blindspots by incorporating \"Advanced Analytics\" perspectives (like JFresh1) to challenge traditional stats like +/-. Stakeholders like JFresh1 explain that elite players are surrounded by high-performing teams, which decreases their value and causes them to be overlooked. Being surrounded by a high-performing team as an elite player would mean that your +/- would be boosted, but in reality, there is a tendency for these players to be viewed as less because they are heavily supported. \n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The primary bias is omitted confounding variables. For example, a defenseman’s $+/-$ is heavily influenced by their \"Zone Start Percentage\" (starting in the defensive vs. offensive zone). If we don't account for this, the model might exhibit confirmation bias, suggesting a player is \"worse\" simply because they are used in a high-leverage defensive role. We mitigate this by including minutes_played and exploring \"Usage\" metrics.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Yes. We will use box plots to show the distribution of stats among finalists versus non-finalists to avoid cherry-picking. Our regression results will include p-values and R-squared values to communicate how much of the \"award reality\" our model actually explains.\n",
    "    \n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> Yes. No PII beyond public \"Player Name\" and \"Team\" is used. No private health data, financial contracts, or personal addresses are included in the dataset.\n",
    " \n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The project will be hosted in a version-controlled environment (GitHub). We will provide a requirements.txt file and a documented Jupyter Notebook so that any researcher can rerun our models to verify our coefficients and feature importance rankings.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> We must ensure that \"Team Market Size\" or \"Team Success\" does not act as a discriminatory proxy. Often, players on \"Original Six\" or high-revenue teams get more media exposure. By using teammate_goals as a control variable, we are actively trying to strip away the \"Good Team Proxy\" to find the individual's true contribution.\n",
    " \n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " \n",
    "> We will test for disparate error rates across positions and age groups. For example, does the model consistently undervalue younger players or players on rebuilding teams? We will calculate the residuals (the difference between predicted and actual votes) to see if the model is biased against certain types of players.\n",
    " \n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " \n",
    "> We chose Save Percentage and Plus-Minus because they are traditional benchmarks. However, we will also consider Goals Above Replacement (GAR) or Expected Goals (xG) as additional metrics to see if they offer higher predictive power than the \"traditional\" stats favored by human voters.\n",
    " \n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " \n",
    "> The model provides \"Feature Importance\" scores, which allow us to explain exactly why a player was predicted as a winner. For example: \"Player X is the predicted Hart winner because his individual contribution to the team's goal differential was in the 99th percentile, outweighing his lower total point count.\"\n",
    " \n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We will explicitly state that our model cannot account for narrative-driven voting. For example, a player having a \"comeback season\" after injury often receives more votes than a statistically identical player who has been consistent for five years. Our model is limited to on-paper performance and cannot measure locker room leadership or media hype.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " \n",
    "> Not relevant to the scope of the project. We are analyzing data only up to 2025.\n",
    " \n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " \n",
    "> While our model is for research, we recognize that \"algorithmic scouting\" can impact player reputations or contract negotiations. If a player or agent feels our model unfairly represents their value, our redress process involves a transparent methodology disclosure. We provide the full list of variables used so that any \"harm\" (such as a low ranking) can be traced back to specific on-ice performance metrics.\n",
    " \n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> If we discover a calculation error or a biased data crawl, we will revert the public version of our findings to the last stable state while we troubleshoot the updated model.\n",
    " \n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> A primary unintended use would be sports gambling. Users might use our aggregate metric to place bets on award winners. To prevent abuse of our model, we will include a disclaimer stating that the model predicts historical statistical trends and cannot account for human voting volatility, injuries, or late-season narratives. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* We have been using iMessage to communicate. We expect each other to get back to one another by the end of the day. \n",
    "\n",
    "* We will meet up to twice a week, Tuesday and Thursday at 1-2pm. \n",
    "\n",
    "* Expectations around tone is to generally be respectful and understanding of each other. \n",
    "\n",
    "* For decision making we plan to go by unanimous vote if possible but majority if needed with compromise for the dissenting voices.\n",
    "\n",
    "* For roles, everyone participates in all steps. People can volunteer for specific tasks for assignments based on their strengths and availability. \n",
    "\n",
    "* Communicate workloads at the start of the week\n",
    "\n",
    "* Get things done a day before for time to review the next day. \n",
    "\n",
    "* Be honest about the issue at hand and give at least one office hours notice to ensure we can get feedback and help from the instructors. At least two group members should try to go to office hours together for project questions to get multiple perspectives and provide explanations to the instructors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atc_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
