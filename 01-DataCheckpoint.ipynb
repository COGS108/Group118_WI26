{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Saaketh Raghava: Background research, Conceptualization, Writing – original draft, Data Curation\n",
    "- Ethan Lee: Background research, Conceptualization, Writing – original draft\n",
    "- Keyura Valalla: Background research, Conceptualization, Writing – original draft\n",
    "- Daniel Stankoulov: Background research, Conceptualization, Writing – original draft, Data Curation\n",
    "- Sophie Mo: Background research, Conceptualization, Writing – original draft\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which combination of player performance statistics can be optimally integrated into a single aggregate metric that most accurately predicts the winners of the NHL regular-season awards (Hart Memorial Trophy, Vezina Trophy, and Norris Trophy)?\n",
    "\n",
    "Specifically, this research seeks to determine how traditional and advanced statistical measures, such as goals, assists, plus/minus, minutes played, and games played, among others, can be weighted and combined to form a composite indicator of player value that best aligns with historical award outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond the physical grit of the sport, hockey is defined by individual \"changemakers\" who shift a team's dynamic toward a Stanley Cup victory. The NHL recognizes this individual excellence through three primary awards: the Hart Memorial Trophy (Most Valuable Player), the Vezina Trophy (Best Goaltender), and the James Norris Memorial Trophy (Best Defenseman). Together, these honors encompass the core roles of the game: forwards, goalies, and defenders, each contributing uniquely to a team's success through scoring, shot-blocking, and net-minding.\n",
    "\n",
    "Despite their prestige, these awards are often criticized for their subjective nature. The Vezina is voted on by NHL General Managers, while the Hart and Norris are decided by the Professional Hockey Writers' Association. This human element introduces significant bias; for example, analyst JFresh<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)</a> noted a recurring bias against elite players on high-performing teams, where individual value is often overshadowed by the quality of a player’s supporting cast in his blog post 'The Hart Trophy is for the Best Player in the League \"umm actually\" shut up!'. \n",
    "\n",
    "Furthermore, the financial stakes are massive: insider Elliotte Friedman noted on the 32 Thoughts podcast<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)</a> that a franchise star like Connor McDavid (who is a 3 time Hart trophy winner) can generate up to an additional $50 million in team revenue.\n",
    "\n",
    "Our project aims to objectify this evaluation process using data-driven modeling to define what truly constitutes \"the best\" at each position. We are building upon—and refining—methodologies seen in prior sports analytics work. For instance, a project exploring the various relationships between players’ birthdays, their experience vs. goal percentage, and age vs. penalty minutes used a variety of charts to identify and display different categorical and numerical data, such as box and scatter plots <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3)</a>. They clearly organize their data in an easily accessible and understandable way—a method we can adopt to make our report more clear and simple to look at. For one of their hypotheses, the conclusion they drew for the relationship between goal percentage and shooting rates was that there wasn’t a strong linear correlation since the coefficient was 0.2. We can apply these learnings to our own project by accounting for the fact that there may be other factors that influence the value of a player, including being surrounded by a good team, as mentioned before by JFresh. \n",
    " \n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) JFresh. (21 Nov 2025) The Hart Trophy is for the Best Player in the League. *JFresh’s Newsletter*. https://jfresh.substack.com/p/the-hart-trophy-is-for-the-best-player\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Sportsnet. (28 Jan 2026) A Conversation With Josh Doan with Elliotte Friedman & Kyle Bukauskas. *Sportsnet Podcasts*. https://www.sportsnet.ca/podcasts/32-thoughts/\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Sling, S. (n.d.) Final Project Draft: STAT 240. *University of Wisconsin–Madison*. https://pages.cs.wisc.edu/~sling/stat-project/stat240.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that a player’s plus-minus will have the most statistically significant weight in determining the Hart and Norris Trophy award winner. This is because it is the most indicative measure of individual importance for team success in a game. A player can score a lot of goals, but if their +- is negative, it likely means that they are contributing to losses more than wins because they are contributing to more points lost than gained. We will use a multivariable regression model to address for team dependency, where we will keep 'teammate_goals' and 'teammate_points' as control variables. This will allow us to determine whether if +- represents individual value or is a simply a product of team success. \n",
    "\n",
    "We believe for the Vezina trophy the most statistically significant weight will be the save percentage. We will create a regression model against 'Shots_Against'. \n",
    "\n",
    "To test which combination of statistics predicts the winner most accurately, we will create a Random Forest model to find feature importance. This will allow us to identify the most optimal combinations of variables that contribute to the players winning the award. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> NHL Players are professional athletes who are aware their stats and names are being tracked and collected by the league and the teams they play for/against.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Some sources of bias include the “East Coast Bias” where players in the eastern time zone are favoured due to game visibility. Another source of bias is reputation bias where veterans receive more votes based on past performance rather than their performance in the current season. To mitigate these biases, we acknowledge that our model predicts voter behavior rather than objective “on-ice” value. \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> The data consists entirely of public figures such as NHL athletes and public award voting history. Therefore, there is no risk of Personally Identifiable Information (PII).\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> As of the 2023-24 season, approximately 90% of the league identifies as white. To ensure our model doesn’t favor specific demographics, we will audit the “Feature Importance” in our model to ensure that it remains tied to on-ice production metrics. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The data provided from NHL is publicly available, meaning that we do not need to protect and secure data as it is already released as a public record.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> An individual has already consented to having their records released via NHL data, meaning that we do not need to remove their information.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> Since the data is derived from public NHL records and used for an academic/research project, we will retain the cleaned dataset for the duration of the analysis and peer review. Once the project is finalized and the report is submitted, the specific processed CSVs/DataFrames will be archived or deleted, as the raw data remains perpetually accessible via the NHL API.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We address blindspots by incorporating \"Advanced Analytics\" perspectives (like JFresh1) to challenge traditional stats like +/-. Stakeholders like JFresh1 explain that elite players are surrounded by high-performing teams, which decreases their value and causes them to be overlooked. Being surrounded by a high-performing team as an elite player would mean that your +/- would be boosted, but in reality, there is a tendency for these players to be viewed as less because they are heavily supported. \n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The primary bias is omitted confounding variables. For example, a defenseman’s $+/-$ is heavily influenced by their \"Zone Start Percentage\" (starting in the defensive vs. offensive zone). If we don't account for this, the model might exhibit confirmation bias, suggesting a player is \"worse\" simply because they are used in a high-leverage defensive role. We mitigate this by including minutes_played and exploring \"Usage\" metrics.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Yes. We will use box plots to show the distribution of stats among finalists versus non-finalists to avoid cherry-picking. Our regression results will include p-values and R-squared values to communicate how much of the \"award reality\" our model actually explains.\n",
    "    \n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> Yes. No PII beyond public \"Player Name\" and \"Team\" is used. No private health data, financial contracts, or personal addresses are included in the dataset.\n",
    " \n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The project will be hosted in a version-controlled environment (GitHub). We will provide a requirements.txt file and a documented Jupyter Notebook so that any researcher can rerun our models to verify our coefficients and feature importance rankings.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> We must ensure that \"Team Market Size\" or \"Team Success\" does not act as a discriminatory proxy. Often, players on \"Original Six\" or high-revenue teams get more media exposure. By using teammate_goals as a control variable, we are actively trying to strip away the \"Good Team Proxy\" to find the individual's true contribution.\n",
    " \n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " \n",
    "> We will test for disparate error rates across positions and age groups. For example, does the model consistently undervalue younger players or players on rebuilding teams? We will calculate the residuals (the difference between predicted and actual votes) to see if the model is biased against certain types of players.\n",
    " \n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " \n",
    "> We chose Save Percentage and Plus-Minus because they are traditional benchmarks. However, we will also consider Goals Above Replacement (GAR) or Expected Goals (xG) as additional metrics to see if they offer higher predictive power than the \"traditional\" stats favored by human voters.\n",
    " \n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " \n",
    "> The model provides \"Feature Importance\" scores, which allow us to explain exactly why a player was predicted as a winner. For example: \"Player X is the predicted Hart winner because his individual contribution to the team's goal differential was in the 99th percentile, outweighing his lower total point count.\"\n",
    " \n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We will explicitly state that our model cannot account for narrative-driven voting. For example, a player having a \"comeback season\" after injury often receives more votes than a statistically identical player who has been consistent for five years. Our model is limited to on-paper performance and cannot measure locker room leadership or media hype.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " \n",
    "> Not relevant to the scope of the project. We are analyzing data only up to 2025.\n",
    " \n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " \n",
    "> While our model is for research, we recognize that \"algorithmic scouting\" can impact player reputations or contract negotiations. If a player or agent feels our model unfairly represents their value, our redress process involves a transparent methodology disclosure. We provide the full list of variables used so that any \"harm\" (such as a low ranking) can be traced back to specific on-ice performance metrics.\n",
    " \n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> If we discover a calculation error or a biased data crawl, we will revert the public version of our findings to the last stable state while we troubleshoot the updated model.\n",
    " \n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> A primary unintended use would be sports gambling. Users might use our aggregate metric to place bets on award winners. To prevent abuse of our model, we will include a disclaimer stating that the model predicts historical statistical trends and cannot account for human voting volatility, injuries, or late-season narratives. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* We have been using iMessage to communicate. We expect each other to get back to one another by the end of the day. \n",
    "\n",
    "* We will meet up to twice a week, Tuesday and Thursday at 1-2pm. \n",
    "\n",
    "* Expectations around tone is to generally be respectful and understanding of each other. \n",
    "\n",
    "* For decision making we plan to go by unanimous vote if possible but majority if needed with compromise for the dissenting voices.\n",
    "\n",
    "* For roles, everyone participates in all steps. People can volunteer for specific tasks for assignments based on their strengths and availability. \n",
    "\n",
    "* Communicate workloads at the start of the week\n",
    "\n",
    "* Get things done a day before for time to review the next day. \n",
    "\n",
    "* Be honest about the issue at hand and give at least one office hours notice to ensure we can get feedback and help from the instructors. At least two group members should try to go to office hours together for project questions to get multiple perspectives and provide explanations to the instructors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
